import sys
import cv2
import torch

from PyQt5 import QtCore
from PyQt5.QtCore import QRunnable, QThreadPool
from PyQt5.QtWidgets import *
from PyQt5.QtGui import QIcon, QPixmap, QImage
from handutil import HandDetector
from ViT import *
from playsound import playsound

class Window(QWidget):
    def __init__(self):
        super().__init__()
        self.init_detector()
        self.init_vit()
        # self.tts = pyttsx3.init()
        self.init_ui()

    def init_detector(self):
        # åˆå§‹åŒ–å®šæ—¶å™¨
        self.timer_camera = QtCore.QTimer()
        self.timer_camera.timeout.connect(self.show_camera)
        # åˆå§‹åŒ–æ‰‹éƒ¨æ£€æµ‹å™¨
        self.detector = HandDetector()
        # åˆå§‹åŒ–æ‘„åƒå¤´
        self.cap = cv2.VideoCapture()
        self.count = -1

    def init_vit(self):
        # self.model = Model()
        pass

    def init_ui(self):
        # è®¾ç½®çª—å£çš„å¤§å°
        self.resize(1000, 500)
        self.center()
        # è®¾ç½®çª—å£çš„æ ‡é¢˜
        self.setWindowTitle('Gesture Recognition ğŸ‘ğŸ»')
        # è®¾ç½®çª—å£çš„å›¾æ ‡ï¼Œå¼•ç”¨å½“å‰ç›®å½•ä¸‹çš„web.pngå›¾ç‰‡
        self.setWindowIcon(QIcon('web.png'))

        hbox = QHBoxLayout()

        # å·¦ä¾§å±•ç¤ºé€‰æ‹©çš„å›¾ç‰‡
        self.picture = QLabel()
        hbox.addWidget(self.picture, 4)

        # å³ä¾§å±•ç¤ºæŒ‰é’®åŠè¯†åˆ«ç»“æœ
        vbox = QVBoxLayout()

        btn_layout = QHBoxLayout()
        # æ‰“å¼€æ‘„åƒå¤´æŒ‰é’®
        self.button_open_camera = QPushButton('æ‰“å¼€æ‘„åƒå¤´', self)
        self.button_open_camera.clicked.connect(self.open_camera)
        # è¯†åˆ«æŒ‰é’®
        btn_recognize = QPushButton('è¯†åˆ«', self)
        btn_recognize.clicked.connect(self.recognize)
        btn_layout.addWidget(self.button_open_camera)
        btn_layout.addWidget(btn_recognize)

        # è¯†åˆ«ç»“æœ
        self.num = QLCDNumber(self)
        self.num.display('0')

        vbox.addLayout(btn_layout)
        vbox.addWidget(self.num)

        hbox.addLayout(vbox,1)

        self.setLayout(hbox)
        # æ˜¾ç¤ºçª—å£
        self.show()

    def recognize(self):
        count = self.detector.finger_count(self.gesture_img)
        if count == -1:
            return
        tts = TTS('sound/' + str(count) + '.mp3')
        QThreadPool.globalInstance().start(tts)

    def open_camera(self):
        if self.timer_camera.isActive() == False:
            result = self.cap.open(0)
            if result == False:
                msg = QMessageBox.Warning(self, u'Warning', u'è¯·æ£€æµ‹ç›¸æœºä¸ç”µè„‘æ˜¯å¦è¿æ¥æ­£ç¡®', buttons=QMessageBox.Ok,
                                          defaultButton=QMessageBox.Ok)
            else:
                self.timer_camera.start(30)
                self.button_open_camera.setText(u'å…³é—­æ‘„åƒå¤´')
        else:
            self.timer_camera.stop()
            self.cap.release()
            self.picture.clear()
            self.button_open_camera.setText(u'æ‰“å¼€æ‘„åƒå¤´')

    def show_camera(self):
        success, img = self.cap.read()
        if success:
            # æ£€æµ‹æ‰‹åŠ¿
            img = self.detector.find_hands(img, draw=True)
            # ç¼“å­˜å½“å‰æ‰‹åŠ¿å›¾ç‰‡
            self.gesture_img = img
            current_count = self.detector.finger_count(img)
            if current_count > -1 and current_count != self.count:
                self.count = current_count
                tts = TTS('sound/' + str(current_count) + '.mp3')
                QThreadPool.globalInstance().start(tts)
                self.num.display(str(current_count))
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            # vit = Model()
            # print(vit.recognize(img))
            show_img = QImage(img.data, img.shape[1], img.shape[0], QImage.Format_RGB888)
            self.picture.setPixmap(QPixmap.fromImage(show_img).scaled(self.picture.width(), self.picture.height()))
            self.picture.setScaledContents(True)

    # æ§åˆ¶çª—å£æ˜¾ç¤ºåœ¨å±å¹•ä¸­å¿ƒ
    def center(self):
        # è·å¾—çª—å£
        qr = self.frameGeometry()
        # è·å¾—å±å¹•ä¸­å¿ƒç‚¹
        cp = QDesktopWidget().availableGeometry().center()
        # æ˜¾ç¤ºåˆ°å±å¹•ä¸­å¿ƒ
        qr.moveCenter(cp)
        self.move(qr.topLeft())

class TTS(QRunnable):
    def __init__(self, filename):
        super(QRunnable,self).__init__()
        self.filename = filename
    def run(self):
        playsound(self.filename)

if __name__ == '__main__':
    #åˆ›å»ºåº”ç”¨ç¨‹åºå’Œå¯¹è±¡
    app = QApplication(sys.argv)
    ex = Window()
    ex.show()
    sys.exit(app.exec_())