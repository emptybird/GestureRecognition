import sys
import cv2
import torch

from PyQt5 import QtCore
from PyQt5.QtCore import QRunnable, QThreadPool
from PyQt5.QtWidgets import *
from PyQt5.QtGui import QIcon, QPixmap, QImage
from handutil import HandDetector
from ViT import *
from playsound import playsound

class Window(QWidget):
    # ViTè¯†åˆ«
    MODEL_VIT  = 0
    # MediaPipeè¯†åˆ«
    MODEL_MEDIAPIPE = 1

    def __init__(self):
        super().__init__()
        self.init_detector()
        self.init_model()
        self.init_ui()

    def init_detector(self):
        # åˆå§‹åŒ–å®šæ—¶å™¨
        self.timer_camera = QtCore.QTimer()
        self.timer_camera.timeout.connect(self.show_camera)
        # åˆå§‹åŒ–æ‰‹éƒ¨æ£€æµ‹å™¨
        self.detector = HandDetector()
        # åˆå§‹åŒ–æ‘„åƒå¤´
        self.cap = cv2.VideoCapture()
        self.count = -1
        self.frameCount = 0
        self.last_num = -1

    def init_model(self):
        self.model = Model()
        self.model_type = Window.MODEL_VIT

    def init_ui(self):
        # è®¾ç½®çª—å£çš„å¤§å°
        self.resize(1000, 500)
        self.center()
        # è®¾ç½®çª—å£çš„æ ‡é¢˜
        self.setWindowTitle('Gesture Recognition ğŸ‘ğŸ»')
        # è®¾ç½®çª—å£çš„å›¾æ ‡ï¼Œå¼•ç”¨å½“å‰ç›®å½•ä¸‹çš„web.pngå›¾ç‰‡
        self.setWindowIcon(QIcon('web.png'))

        hbox = QHBoxLayout()

        # å·¦ä¾§å±•ç¤ºé€‰æ‹©çš„å›¾ç‰‡
        self.picture = QLabel()
        hbox.addWidget(self.picture, 4)

        # å³ä¾§å±•ç¤ºæŒ‰é’®åŠè¯†åˆ«ç»“æœ
        vbox = QVBoxLayout()

        btn_layout = QHBoxLayout()
        # æ‰“å¼€æ‘„åƒå¤´æŒ‰é’®
        self.button_open_camera = QPushButton('æ‰“å¼€æ‘„åƒå¤´', self)
        self.button_open_camera.clicked.connect(self.open_camera)
        # åˆ‡æ¢æŒ‰é’®
        self.btn_switch_model = QPushButton('ViT', self)
        self.btn_switch_model.clicked.connect(self.switch_model_type)
        btn_layout.addWidget(self.button_open_camera)
        btn_layout.addWidget(self.btn_switch_model)

        # è¯†åˆ«ç»“æœ
        self.num = QLCDNumber(self)
        self.num.display('0')

        vbox.addLayout(btn_layout)
        vbox.addWidget(self.num)

        hbox.addLayout(vbox,1)

        self.setLayout(hbox)
        # æ˜¾ç¤ºçª—å£
        self.show()

    def switch_model_type(self):
        self.model_type = 1 - self.model_type
        if self.model_type == Window.MODEL_VIT:
            self.btn_switch_model.setText("ViT")
        else:
            self.btn_switch_model.setText("MediaPipe")

    def open_camera(self):
        if self.timer_camera.isActive() == False:
            result = self.cap.open(0)
            if result == False:
                msg = QMessageBox.Warning(self, u'Warning', u'è¯·æ£€æµ‹ç›¸æœºä¸ç”µè„‘æ˜¯å¦è¿æ¥æ­£ç¡®', buttons=QMessageBox.Ok,
                                          defaultButton=QMessageBox.Ok)
            else:
                self.timer_camera.start(30)
                self.button_open_camera.setText(u'å…³é—­æ‘„åƒå¤´')
        else:
            self.timer_camera.stop()
            self.cap.release()
            self.picture.clear()
            self.button_open_camera.setText(u'æ‰“å¼€æ‘„åƒå¤´')
            self.num.display("0")

    def show_camera(self):
        success, img = self.cap.read()
        if success:
            # æ£€æµ‹æ‰‹åŠ¿
            img = self.detector.find_hands(img, draw=self.model_type == Window.MODEL_MEDIAPIPE)
            # æ‰‹æŒç›®æ ‡æ£€æµ‹
            palm_rect = self.detector.palm_detection(img, cv2)

            if self.model_type == Window.MODEL_MEDIAPIPE:
                # ç¼“å­˜å½“å‰æ‰‹åŠ¿å›¾ç‰‡
                self.gesture_img = img
                current_count = self.detector.finger_count(img)
                if current_count == self.count:
                    self.frameCount += 1
                else:
                    self.count = current_count
                    self.frameCount = 0

                if current_count > -1 and current_count != self.last_num and self.frameCount >= 4:
                    self.last_num = current_count
                    tts = TTS('sound/' + str(current_count) + '.mp3')
                    QThreadPool.globalInstance().start(tts)
                    self.num.display(str(current_count))
            elif palm_rect:
                vit = ViT(self.model, img, palm_rect, self.num)
                QThreadPool.globalInstance().start(vit)

            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            show_img = QImage(img.data, img.shape[1], img.shape[0], QImage.Format_RGB888)
            self.picture.setPixmap(QPixmap.fromImage(show_img).scaled(self.picture.width(), self.picture.height()))
            self.picture.setScaledContents(True)

    # æ§åˆ¶çª—å£æ˜¾ç¤ºåœ¨å±å¹•ä¸­å¿ƒ
    def center(self):
        # è·å¾—çª—å£
        qr = self.frameGeometry()
        # è·å¾—å±å¹•ä¸­å¿ƒç‚¹
        cp = QDesktopWidget().availableGeometry().center()
        # æ˜¾ç¤ºåˆ°å±å¹•ä¸­å¿ƒ
        qr.moveCenter(cp)
        self.move(qr.topLeft())
# è¯­éŸ³æ’­æ”¾
class TTS(QRunnable):
    def __init__(self, filename):
        super(QRunnable,self).__init__()
        self.filename = filename
    def run(self):
        playsound(self.filename)

# ViTåˆ†ç±» è¯­éŸ³æ’­æ”¾
class ViT(QRunnable):
    def __init__(self, model, img, palm_rect, view):
        super(QRunnable,self).__init__()
        self.model = model
        self.img = img
        self.palm_rect = palm_rect
        self.view = view

    def run(self):
        if self.palm_rect:
            try:
                resized_img = self.resize_img(self.img, self.palm_rect)
                result = self.model.recognize(resized_img)
                finger_count = torch.max(result, 1)[1].data.numpy()[0]
                print(finger_count)
                # playsound('sound/' + str(finger_count) + '.mp3')
                self.view.display(str(finger_count))
            except Exception as e:
                print(str(e))

    def resize_img(self, img, palm_rect):
        if palm_rect:
            border_w = min(palm_rect[2], img.shape[1])
            border_h = min(palm_rect[3], img.shape[0])
            region = img[palm_rect[1]:border_h, palm_rect[0]:border_w]
            w, h = border_w - palm_rect[0], border_h - palm_rect[1]
            max_length = max(w, h)
            ratio = 64.0 / max_length
            new_w, new_h = int(ratio * w), int(ratio * h)
            resized = cv2.resize(region, (new_w, new_h))

            W, H = 64, 64
            top = bottom = (H - new_h) // 2
            if top + bottom + new_h < H:
                bottom += (H - top - bottom - new_h)
            left = right =  (W - new_w) // 2
            if left + right + new_w < W:
                right += (W - left - right - new_w)
            pad_image = cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(0,0,0))
            # cv2.imshow("resize image",pad_image)
            return pad_image

if __name__ == '__main__':
    #åˆ›å»ºåº”ç”¨ç¨‹åºå’Œå¯¹è±¡
    app = QApplication(sys.argv)
    ex = Window()
    ex.show()
    sys.exit(app.exec_())